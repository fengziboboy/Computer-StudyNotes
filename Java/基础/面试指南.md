
# Java面试指南

# 常见面试题

1. Java的第一印象、特点、区别于其他语言的？ 见[《Java基础大杂烩》](./Java基础大杂烩.md)
2. 异常：Error、Exception、Throwable？见[《异常处理》](./异常处理.md)
3. 谈谈 final、finally、 finalize 有什么不同?
    - final：是可以用来修饰类、方法、变量。明确语义和意图，不可修改，也保证安全。减少同步开销，省去一些防御性拷贝的必要。
      - 类： 不可继承扩展
        - 在java.lang 包下面的很多类，相当 一部分都被声明成为 final class?在第三方类库的一些基础类中同样如此，这可以有效避免 API 使用者更改基础功能
      - 变量： 不可修改。 
        - final 字段对性能的影 响，大部分情况下，并没有考虑的必要。
        - final 不是 immutable!：
      - 方法： 不可重写（override）
    - finally：是Java 保证重点代码一定要被执行的一种机制。
      - 经常用在try-catch-finally中类似JDBC关闭连接、保证unlock锁等动作，不过关闭资源推荐使用try-with-resources语句。
    - finalize： 是基础类java.lang.Object的一个方法，设计目的是保证对象在被垃圾收集前完成特定资源的回收。（不在推荐使用）
      - 不推荐原因：你无法保证 finalize 什么时候执行，执行的是否符合预期。使用不当会 影响性能，导致程序死锁、挂起等。
    >面试官还可以考察你对性能、并发、对象生命周期或垃圾 收集基本过程等方面的理解.


4. 强引用、软引用、弱引用、幻象引用有什么区别?


# 集合

## ArrayList、Vector、LinkedList有何区别？

- Vector 是 Java 早期提供的**线程安全**的动态数组，如果不需要线程安全，并不建议选择， 毕竟同步是有额外开销的。扩容会创建新的数组，并拷贝原来的数组数据。 扩容1倍。 
- ArrayList 是应用更加广泛的动态数组实现，它本身不是线程安全的，所以性能要好很多。扩容50%。
- LinkedList 是双向链表，不需要调整容量，**不是线程安全**。


如果事先可以估计到，应用操作是偏向于插入、删除，还是随机访问较多，就可以针对性的进行选择。

* **TreeSet** 支持自然顺序访问，但是添加、删除、包含等操作要相对低效(log(n) 时 间)。
* **HashSet** 则是利用哈希算法，理想情况下，如果哈希散列正常，可以提供常数时间的添 加、删除、包含等操作，但是它不保证有序。
* **LinkedHashSet**，内部构建了一个记录插入顺序的双向链表，因此提供了按照插入顺序 遍历的能力，与此同时，也保证了常数时间的添加、删除、包含等操作，这些操作性能略 低于 HashSet，因为需要维护链表的开销。
  * 在遍历元素时，HashSet 性能受自身容量影响，所以初始化时，除非有必要，不然不要 将其背后的 HashMap 容量设置过大。
  * 而对于 LinkedHashSet，由于其内部链表提供的 方便，遍历性能只和元素多少有关系。


**集合排序**

 Java 提供的默认排序算法，具体是什么排序方 式以及设计思路等。

这个问题本身就是有点陷阱的意味，因为需要区分是 Arrays.sort() 还是 Collections.sort() (底层是调用 Arrays.sort());什么数据类型;多大的数据集(太小的数据集，复杂排序 是没必要的，Java 会直接进行二分插入排序)等。
对于原始数据类型，目前使用的是所谓双轴快速排序(Dual-Pivot QuickSort)，是一 种改进的快速排序算法，早期版本是相对传统的快速排序，你可以阅读源码。


而对于对象数据类型，目前则是使用TimSort，思想上也是一种归并和二分插入排序 (binarySort)结合的优化排序算法。TimSort 并不是 Java 的独创，简单说它的思路是 查找数据集中已经排好序的分区(这里叫 run)，然后合并这些分区来达到排序的目的。


另外，Java 8 引入了并行排序算法(直接使用 parallelSort 方法)，这是为了充分利用现 代多核处理器的计算能力，底层实现基于 fork-join 框架(专栏后面会对 fork-join 进行相 对详细的介绍)，当处理的数据集比较小的时候，差距不明显，甚至还表现差一点;但是， 当数据集增长到数万或百万以上时，提高就非常大了，具体还是取决于处理器和系统环境。


##  Hashtable、HashMap、TreeMap 有什么不同?

- Hashtable： 同步，不支持null键和值。
- HashMap： 不同步，支持 null 键和值。 存取时间接近常数。
- TreeMap 则是基于红黑树的一种提供**顺序**访问的 Map，它的 get、 put、remove 之类操作都是 O(log(n))的时间复杂度 


**Map**

**继承关系**
- Dictionary：HashTable：Properties
- AbstractMap： HashMap：LinkedHashMap、TreeMap、EnumMap
- EnumMap、HashMap、SortedMap


HashMap 的性能表现非常依赖于哈希码的有 效性，请务必掌握 **hashCode 和 equals **的一些基本约定，比如:

- equals 相等，hashCode 一定要相等。
- 重写了 hashCode 也要重写 equals。
- hashCode 需要保持一致性，状态改变返回的哈希值仍然要一致。
- equals 的对称、反射、传递等特性。


LinkedHashMap 和 TreeMap 都可以保证某种**顺序**，但二者还是非常不同的。

- LinkedHashMap 通常提供的是**遍历顺序符合插入顺序**，它的实现是通过为条目(键值 对)维护一个双向链表。注意，通过特定构造函数，我们可以创建反映访问顺序的实例， 所谓的 put、get、compute 等，都算作“访问”。 **插入顺序就是遍历读取的顺序？ get操作也算是访问，如果get过会被放在前面**
  - 用处：我们构建一个空间占用敏感的资源池，希望可以自动将最不常被访问的对象释放掉，这就可以利用 LinkedHashMap 提供的机制来实现。
  - 构建一个具有优先级的调度系统的问题，其本质就是个 典型的优先队列场景，Java 标准库提供了基于二叉堆实现的 PriorityQueue，它们都是依 赖于**同一种排序机制**，当然也包括 TreeMap 的马甲 TreeSet。


### HashMap 源码分析

**HashMap 内部实现基本点分析**

1. HashMap内部结构可以看作是数组(Node<K,V>[] table)和链表结合组成的复合结构，数组被分为一个个桶(bucket)，通过哈希值决定了 键值对在这个数组的寻址;
2. 哈希值相同的键值对，以链表形式存储，链表大小超过（8），就会被改造为树形结构。


3. putVal 方法本身逻辑非常集中，从初始化、扩容到树化，全部都和它有关。

```java
final V putVal(int hash, K key, V value, boolean onlyIfAbent, boolean evit) {
    Node<K,V>[] tab; Node<K,V> p; int , i;
    if ((tab = table) == null || (n = tab.length) = 0)
        n = (tab = resize()).length;
    if ((p = tab[i = (n - 1) & hash]) == ull)
        tab[i] = newNode(hash, key, value, nll);
    else {
        // ...
        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for first
           treeifyBin(tab, hash);
        //  ...
} }
```

- 如果表格是 null，resize 方法会负责初始化它，这从 tab = resize() 可以看出。


4. **resize方法**兼顾两个职责：
   - 创建**初始存储表格**（如上一段代码）
   - 在容量不满足需求的时候（如下一段代码），进行扩容(resize)。


- `threshold=newCap * loadFator;` 如果构建HashMap时没指定就用默认常量值。
- threshold通常以倍数进行调整(newThr = oldThr << 1)。

```java
if (++size > threshold) resize();
```

- 具体键值对在哈希表中的位置(数组 index)取决于下面的位运算: `i = (n - 1) & hash`。
  
- **hash值**
  - 为什么这里需要将高位数据移位到低位进行异或运算呢?
    >这是因为有些数据计算出的哈希值差异主要在高位，而 HashMap 里的哈希 寻址是忽略容量以上的高位的，那么这种处理就可以有效避免类似情况下的哈希碰撞。
```java
static final int hash(Object kye) {
  int h;
  return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>>16;
}
```

- 扩容后，需要将老的数组中的元素重新放置到新的数组。这是扩容的主要开销来源。



**容量(capacity)和负载系数(load factor)**


容量和负载系数**决定了可用的桶的数量**，空桶太多会浪费空间，如果使用的太满则
会严重影响操作的性能。极端情况下，假设只有一个桶，那么它就退化成了链表。


既然容量和负载因子这么重要，我们**在实践中应该如何选择**呢?

- 预先设置的容量需要满足，大于“预估元素数量 / 负载因子”，同时它是 2 的幂 数，结论已经非常清晰了。

- 如果没有特别需求，不要轻易进行更改，因为 JDK 自身的默认负载因子是非常符合通用 场景的需求的。
- 
- 如果确实需要调整，建议不要设置超过 0.75 的数值，因为会显著增加冲突，降低 HashMap 的性能。
- 如果使用太小的负载因子，按照上面的公式，预设容量值也进行调整，否则可能会导致更加频繁的扩容，增加无谓的开销，本身访问性能也会受影响。




**树化**

对应逻辑主要在 putVal 和 treeifyBin 中：


```java
 final void treeifyBin(Node<K,V>[] tab, int hash) {
    int n, index; Node<K,V> e;
    if (tab == null || (n = tab.length) < MIN_TREEIFY_CAPACITY) 
      resize();
    else if ((e = tab[index - (n - 1) & hash]) != null){
      //树化逻辑
    }

```

当 bin 的数量大于 TREEIFY_THRESHOLD 时:
- 如果容量小于 MIN_TREEIFY_CAPACITY，只会进行简单的扩容。 
- 如果容量大于 MIN_TREEIFY_CAPACITY ，则会进行树化改造。


## 如何保证容器是线程安全的?ConcurrentHashMap 如何实现高 效地线程安全?


### ConcurrentHashMap 分析

**演化的过程**


#### 1. 早期Java7： 分段、分离锁
- 分离锁，也就是将内部进行分段(Segment)，里面则是 HashEntry 的数组，和 HashMap 类似，哈希相同的条目也是以链表形式存放。
- HashEntry 内部使用 volatile 的 value 字段来保证可见性，也利用了不可变对象的机制以改进利用 Unsafe 提供的底层能力，比如 volatile access，去直接完成部分操作，以最优化性能，毕竟 Unsafe 中的很多操作都是 JVM intrinsic 优化过的。
- **Segment 的数量**由所谓的 concurrentcyLevel 决定，默认是 16，也可以 在相应构造函数直接指定。注意，Java 需要它是 2 的幂数值

-  get 操作：需要保证的是可见性， 所以并没有什么同步逻辑。
   -  计算hash，找到位置
   -  Unsafe直接进行volatile access
-  put 操作： 首先是通过二次哈希避免哈希冲突，然后以 Unsafe 调用方式，直接获 取相应的 Segment，然后进行线程安全的 put 操作。
   -  put要先获取锁，锁的是segment。
   -  ConcurrentHashMap 会获取再入锁，以保证数据一致性，Segment 本身就是基于 ReentrantLock 的扩展实现，所以，在并发修改期间，相应 Segment 是被锁定的。
   -  在最初阶段，进行重复性的扫描，以确定相应 key 值是否已经在数组里面，进而决定是 更新还是放置操作。重复扫描、检测冲突是 ConcurrentHashMap 的常见技巧。
   -  扩容是单独对Segment扩容。
-  **分离锁副作用**： size 方法 计算 和初始化操作耗时。如果不进行同步，简单的计算所有 Segment 的总值，可能会因为并发 put，导致结 果不准确，但是直接锁定所有 Segment 进行计算，就会变得非常昂贵。
   -  ConcurrentHashMap 的实现是通过重试机制(RETRIES_BEFORE_LOCK，指定重 试次数 2)，来试图获得可靠值。
   -  如果没有监控到发生变化(通过对比 Segment.modCount)，就直接返回，否则获取锁进行操作。


#### 2. Java8 的一些变化：去掉分段，CAS、volatile、Unsafe

1. 其内部仍然有 Segment 定义，但仅仅是**为了保证序列化时的兼容性**而已，**不再有任何结构上的用处**。
2. 因为不再使用 Segment，**初始化操作大大简化**，修改为 **lazy-load** 形式，这样可以有效 避免初始开销。
3. 数据存储利用 volatile 来保证可见性。
4. 使用 CAS 等操作，在特定场景进行无锁并发操作。
5. 使用 Unsafe、LongAdder 之类底层手段，进行极端情况的优化。
6. 1.8以后的锁的颗粒度，是加在链表头上的


具体看数据存储内部实现：
- key是final的，因为在生命周期中，一个条目的 Key不可能变化;
- val声明为volatile，以保证其可见性。


**put方法的实现**

补充源码


- 在同步逻辑上，它使用的是 synchronized。 
  >synchronized相比于 ReentrantLock，它可以减少内存消耗，这是个 非常大的优势。

- size计算： 
  - 真正的逻辑是在 sumCount 方法中。 思路仍然和以前类似，都是分而治之的进行计数，然后求和处理，但实现却 基于一个奇怪的 CounterCell。
  - 对于 CounterCell 的操作，是基于 java.util.concurrent.atomic.LongAdder 进行 的，是一种 JVM 利用空间换取更高效率的方法，利用了Striped64内部的复杂逻辑。


