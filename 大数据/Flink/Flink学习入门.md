# BOBO学习Flink

## 学习资料-巨人肩膀

### 文档
- 官方文档（中文）：https://flink.apache.org/zh/

### 书籍
- 《基于Apache Flink的流处理》
- 《StreamingSystems》 英文

### 视频教程
1. https://github.com/flink-china/flink-training-course
2. 拉勾教育-flink教程

## 基础篇

**数据流上的有状态计算**

### 优势、对比
- 它的主要特性包括： 批流一体化、精密的状态管理、事件时间支持以及精确一次的状态一致性保障等。
- Flink 不仅可以运行在包括 YARN、 Mesos、Kubernetes 在内的多种资源管理框架上，还支持在裸机集群上独立部署。
- 在启用高可用选项的情况下，它不存在单点失效问题。
  >事实证明，Flink 已经可以扩展到数千核心，其状态可以达到 TB 级别，且仍能保持高吞吐、低延迟的特性。



### 基础特性
**Flink自身特点：**
- 所有流式场景
   * 事件驱动应用
   * 流批分析
   * 数据管道 & ETL

* 正确性保证
  * Exactly-once 状态一致性
  * 事件时间处理
  * 成熟的迟到数据处理

* 分层 API
  * SQL on Stream & Batch Data
  * DataStream API & DataSet API
  * ProcessFunction (Time & State)

* 聚焦运维
  * 灵活部署
  * 高可用
  * 保存点

* 大规模计算
  * 水平扩展架构
  * 支持超大状态
  * 增量检查点机制

* 性能卓越
  * 低延迟
  * 高吞吐
  * 内存计算


- **流处理特性**：
  * 支持高吞吐、低延迟、高性能的流处理 
  * 支持带有事件时间的窗口(Window)操作 
  * 支持有状态计算的Exactly-once语义 
  * 支持高度灵活的窗口(Window)操作,支持基于time、count、session,以及data-driven的窗口操作 
  * 支持具有Backpressure功能的持续流模型 
  * 支持基于轻量级分布式快照(Snapshot)实现的容错 
  * 一个运行时同时支持Batch on Streaming处理和Streaming处理 
  * Flink在JVM内部实现了自己的内存管理 
  * 支持迭代计算 
  * 支持程序自动优化:避免特定情况下Shuffle、排序等昂贵操作,中间结果有必要进行缓存


**API支持**
  * 对Streaming数据类应用,提供DataStream API 
  * 对批处理类应用,提供DataSet API(支持Java/Scala) 


- **Libraries支持**
  * 支持机器学习(FlinkML) 
  * 支持图分析(Gelly) 
  * 支持关系数据处理(Table) 
  * 支持复杂事件处理(CEP) 

- **整合支持**
  * 支持Flink on YARN 
  * 支持HDFS 
  * 支持来自Kafka的输入数据 
  * 支持Apache HBase 
  * 支持Hadoop程序 
  * 支持Tachyon 
  * 支持ElasticSearch 
  * 支持RabbitMQ 
  * 支持Apache Storm 
  * 支持S3 
  * 支持XtreemFS 



### Flink核心概念

#### Streams（流）

流分为**有界流和无界流**。
  * 有界流指的是**有固定大小**，不随时间增加而增长的数据，比如我们保存在 Hive 中的一个表；
  * 而无界流指的是数据**随着时间增加而增长**，计算状态持续进行，比如我们消费 Kafka 中的消息，消息持续不断，那么计算也会持续进行不会结束。
#### State（状态）
所谓的状态指的是在进行流式**计算过程中的信息**。
  * 一般用作容错恢复和持久化，**流式计算在本质上是增量计算，也就是说需要不断地查询过去的状态**。
  * 状态在 Flink 中有十分重要的作用，例如为了确保 Exactly-once 语义需要将数据写到状态中；
  * 此外，状态的持久化存储也是集群出现 Fail-over 的情况下自动重启的前提条件。
  * 只有在每一个单独的事件上进行转换操作的应用才不需要状态，换言之，每一个具有一定复杂度的流处理应用都是有状态的。

Flink 提供了许多**状态管理相关的特性支持**，其中包括：
  * **多种状态基础类型**：Flink 为多种不同的数据结构提供了相对应的状态基础类型，例如原子值（value），列表（list）以及映射（map）。开发者可以基于处理函数对状态的访问方式，选择最高效、最适合的状态基础类型。
  * 插件化的State Backend：State Backend 负责管理应用程序状态，并在需要的时候进行 checkpoint。Flink 支持多种 state backend，可以将状态存在内存或者 RocksDB。RocksDB 是一种高效的嵌入式、持久化键值存储引擎。Flink 也支持插件式的自定义 state backend 进行状态存储。
  * **精确一次语义**：Flink 的 checkpoint 和故障恢复算法保证了故障发生后应用状态的一致性。因此，Flink 能够在应用程序发生故障时，对应用程序透明，不造成正确性的影响。
  * **超大数据量状态**：Flink 能够利用其异步以及增量式的 checkpoint 算法，存储数 **TB** 级别的应用状态。
  * **可弹性伸缩的应用**：Flink 能够通过在更多或更少的工作节点上对状态进行重新分布，支持有状态应用的分布式的横向伸缩。


#### Time（时间）
时间是流处理应用另一个重要的组成部分。因为事件总是在特定时间点发生，所以大多数的事件流都拥有事件本身所固有的时间语义。进一步而言，许多常见的流计算都基于时间语义，例如窗口聚合、会话计算、模式检测和基于时间的 join。流处理的一个重要方面是应用程序如何衡量时间，即区分**事件时间**（event-time）和**处理时间**（processing-time）。

Flink 提供了丰富的**时间语义支持**。
* **事件时间模式**：使用事件时间语义的流处理应用根据事件本身自带的时间戳进行结果的计算。因此，无论处理的是历史记录的事件还是实时的事件，事件时间模式的处理总能保证结果的准确性和一致性。
* **Watermark 支持**：Flink 引入了 watermark 的概念，用以衡量事件时间进展。Watermark 也是一种平衡处理延时和完整性的灵活机制。
* **迟到数据处理**：当以带有 watermark 的事件时间模式处理数据流时，在计算完成之后仍会有相关数据到达。这样的事件被称为迟到事件。Flink 提供了多种处理迟到数据的选项，例如将这些数据重定向到旁路输出（side output）或者更新之前完成计算的结果。
* **处理时间模式**：除了事件时间模式，Flink 还支持处理时间语义。处理时间模式根据处理引擎的机器时钟触发计算，一般适用于有着严格的低延迟需求，并且能够容忍近似结果的流处理应用。

  * Flink 支持了 Event time、Ingestion time、Processing time 等多种时间语义，
  * 时间是我们在进行 Flink 程序开发时判断业务状态是否滞后和延迟的重要依据。
* **API**：
  * Flink 自身提供了不同级别的抽象来支持我们开发流式或者批量处理程序，
  * 由上而下可分为 SQL / Table API、DataStream API、ProcessFunction 三层，
  * 开发者可以根据需要选择不同层级的 API 进行开发。

### Flink 编程模型和流式处理

Flink 程序的基础构建模块是**流**（Streams）和**转换**（Transformations），每一个**数据流**起**始于**一个或多个 **Source**，并**终止于**一个或多个**Sink**。数据流类似于**有向无环图**（DAG）。

在分布式运行环境中，Flink 提出了算子链的概念，Flink 将多个算子放在一个任务中，由同一个线程执行，减少线程之间的切换、消息的序列化/反序列化、数据在缓冲区的交换，减少延迟的同时提高整体的吞吐量。

在并行环境下，Flink 将多个 operator 的子任务链接在一起形成了一个task，每个 task 都有一个独立的线程执行。

### Flink 集群模型和角色
在实际生产中，Flink 都是以集群在运行，在运行的过程中包含了两类进程。

* **JobManager**：它扮演的是集群管理者的角色，
  * 负责调度任务、协调 checkpoints、协调故障恢复、收集 Job 的状态信息，
  * 并管理 Flink 集群中的从节点 TaskManager。
* **TaskManager**：
  * 实际负责执行计算的 Worker，在其上执行 Flink Job 的一组 Task；
  * TaskManager 还是所在节点的管理员，它负责把该节点上的服务器信息比如内存、磁盘、任务运行情况等向 JobManager 汇报。
* **Client**：
  * 用户在提交编写好的 Flink 工程时，会先创建一个客户端再进行提交，这个客户端就是 Client，
  * Client 会根据用户传入的参数选择使用 yarn per job 模式、stand-alone 模式还是 yarn-session 模式将 Flink 程序提交到集群。

### Flink资源和资源组

slot仅仅用来对内存做隔离，对CPU不起作用。 共享TCP连接。

### 批处理 VS 流处理

批处理是处理有界数据流时的范例。在这种操作模式下，您可以选择在生成任何结果之前摄取整个数据集，这意味着，例如，可以对数据进行排序、计算全局统计或生成总结所有输入的最终报告。

流处理涉及无限制的数据流。至少从概念上来说，输入可能永远不会结束，因此您必须在数据到达时不断处理它。

### 事件驱动型应用

事件驱动型应用是一类具有状态的应用，它从一个或多个事件流提取数据，并根据到来的事件触发计算、状态更新或其他外部动作。

事件驱动型应用是在计算存储分离的传统应用基础上进化而来。

- **在传统架构中，应用需要读写远程事务型数据库**。
- Flink中，事件驱动型应用是**基于状态化流处理**来完成。在该设计中，**数据和计算不会分离**，应用只需访问本地（内存或磁盘）即可获取数据。系统**容错性**的实现依赖于**定期向远程持久化**存储写入**checkpoint**。

**优势**：
- 事件驱动型应用无须查询远程数据库，本地数据访问使得它具有更高的吞吐和更低的延迟。
- 而由于定期向远程持久化存储的 checkpoint 工作可以异步、增量式完成，因此对于正常事件处理的影响甚微。
- 传统分层架构下，通常多个应用会共享同一个数据库，因而任何对数据库自身的更改（例如：由应用更新或服务扩容导致数据布局发生改变）都需要谨慎协调。反观事件驱动型应用，由于只需考虑自身数据，因此在更改数据表示或服务扩容时所需的协调工作将大大减少。
  >自身数据时效性？

**如何支持：**事件驱动型应用会受制于底层流处理系统对时间和状态的把控能力
- 提供了一系列丰富的状态操作原语，允许以精确一次的一致性语义合并海量规模（TB 级别）的状态数据。
- Flink 还支持事件时间和自由度极高的定制化窗口逻辑，而且它内置的 ProcessFunction 支持细粒度时间控制，方便实现一些高级业务逻辑。
- Flink 还拥有一个复杂事件处理（CEP）类库，可以用来检测数据流中的模式
- Savepoint 是一个一致性的状态映像，它可以用来初始化任意状态兼容的应用。在完成一次 savepoint 后，即可放心对应用升级或扩容，还可以启动多个版本的应用来完成 A/B 测试。

### 数据分析应用
数据分析任务需要从原始数据中提取有价值的信息和指标。

- **传统**的分析方式通常是**利用批查询**，或将事件记录下来并基于此有限数据集构建应用来完成。
  - 为了得到最新数据的分析结果，必须先将它们加入分析数据集并重新执行查询或运行应用，随后将结果写入存储系统或生成报告。
- **Flink：**
  - 借助一些先进的流处理引擎，还可以实时地进行数据分析。
  - 和传统模式下读取有限数据集不同，流式查询或应用会接入实时事件流，并随着事件消费持续产生和更新结果。
  - 仪表展示应用可以相应地从外部数据库读取数据或直接查询应用的内部状态。

**流处理优势：**
- 和批量分析相比，由于流式分析省掉了周期性的数据导入和查询过程，因此从事件中获取指标的**延迟更低**。
- 批量查询必须处理那些由定期导入和输入有界性导致的人工数据边界，而流式查询则无须考虑该问题。
- 流式分析会简化应用抽象。批量查询的流水线通常由多个独立部件组成，需要周期性地调度提取数据和执行查询。如此复杂的流水线操作起来并不容易，一旦某个组件出错将会影响流水线的后续步骤。

**如何支持：**
- 它内置了一个符合 ANSI 标准的 SQL 接口，将批、流查询的语义统一起来。无论是在记录事件的静态数据集上还是实时事件流上，相同 SQL 查询都会得到一致的结果。
-  Flink 还支持丰富的用户自定义函数，允许在 SQL 中执行定制化代码。
-  可以利用 Flink DataStream API 和 DataSet API 进行更低层次的控制。
-  Flink 的 Gelly 库为基于批量数据集的大规模高性能图分析提供了算法和构建模块支持。


### Flink Vs Spark

**相同点**：
- 都基于内存计算；
- 都有统一的批处理和流处理 API，都支持类似 SQL 的编程接口；
- 都支持很多相同的转换操作，编程都是用类似于 Scala Collection API 的函数式编程模式；
- 都有完善的错误恢复机制；
- 都支持 Exactly once 的语义一致性。

**不同点**，可以从 4 个不同的角度来看：
- 从**流处理的角度**来讲，
  - Spark 基于微批量处理，把流数据看成是一个个小的批处理数据块分别处理，所以延迟性只能做到秒级。
  - 而 Flink 基于每个事件处理，每当有新的数据输入都会立刻处理，是真正的流式计算，支持毫秒级计算。
  - 由于相同的原因，Spark 只支持基于时间的窗口操作（处理时间或者事件时间），
  - 而 Flink 支持的窗口操作则非常灵活，不仅支持时间窗口，还支持基于数据本身的窗口，开发者可以自由定义想要的窗口操作。

- 从 SQL 功能的角度来讲，Spark 和 Flink 分别提供 SparkSQL 和 Table API 提供 SQL 交互支持。两者相比较，Spark 对 SQL 支持更好，相应的优化、扩展和性能更好，而 Flink 在 SQL 支持方面还有很大提升空间。

- 从迭代计算的角度来讲，Spark 对机器学习的支持很好，因为可以在内存中缓存中间计算结果来加速机器学习算法的运行。但是大部分机器学习算法其实是一个有环的数据流，在 Spark 中，却是用无环图来表示。而 Flink 支持在运行时间中的有环数据流，从而可以更有效的对机器学习算法进行运算。从相应的生态系统角度来讲，Spark 的社区无疑更加活跃。Spark 可以说有着 Apache 旗下最多的开源贡献者，而且有很多不同的库来用在不同场景。而 Flink 由于较新，现阶段的开源社区不如 Spark 活跃，各种库的功能也不如 Spark 全面。但是 Flink 还在不断发展，各种功能也在逐渐完善。小结


对于以下场景，你可以选择 Spark。数据量非常大而且逻辑复杂的批数据处理，并且对计算效率有较高要求（比如用大数据分析来构建推荐系统进行个性化推荐、广告定点投放等）；基于历史数据的交互式查询，要求响应较快；基于实时数据流的数据处理，延迟性要求在在数百毫秒到数秒之间。Spark 完美满足这些场景的需求， 而且它可以一站式解决这些问题，无需用别的数据处理平台。

由于 Flink 是为了提升流处理而创建的平台，所以它适用于各种需要非常低延迟（微秒到毫秒级）的实时数据处理场景，比如实时日志报表分析。而且 Flink 用流处理去模拟批处理的思想，比 Spark 用批处理去模拟流处理的思想扩展性更好，所以我相信将来 Flink 会发展的越来越好，生态和社区各方面追上 Spark。

#### Storm