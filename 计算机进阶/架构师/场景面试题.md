
# 数据库


## 数据库迁移如何同步保证增量数据不丢？

参考：
- https://www.cnblogs.com/czsy/archive/2022/12/15/16985912.html

### 业务双写

**优缺点**

- 优点： 1. 简单易操作 2.无需中间件支持 3.**无延迟**

- 缺点： **对业务侵入大**，需要在新老系统维护对应的数据同步逻辑


**操作步骤**：

1. 同步全量（选个时间点）
    1. 通过sql扫表，如果表比较大可以按月或者按天扫，优点是操作简单，缺点是需要人工一直介入，且扫表会对数据库造成一定压力，影响业务功能的稳定性
    2. 同步离线表取数，将离线表的数据发送到mq或者kafaka，消费后进行数据同步
    3. 存量数据同步的时候也需要注意的是数据的版本问题，如果不存在就新增，如果存在就判断时间戳或版本号，总之就是将最新的数据更新进去，老版本数据抛弃。


2. 同步增量（增量先跑，避免丢数据）
    1. 将老系统中所有新增、更新的地方都写上数据同步逻辑.
    2. 在同步数据的时候，除了新老模型字段的映射逻辑以外，当操作是**新增**的时候，直接新增新表数据，当操作是**更新**的时候，**如果新表没有对应信息，那么查一下老表的数据**，然后映射到新模型数据结构再新增到新表
    3. 更新新模型的时候可能存在并发问题，这时候我们插入的时候要检查时间戳或者版本号，如果库内数据早于自己，就更新，否则就丢弃。
 

同步代码的复用性差，业务代码内部维护的增量逻辑和存量同步的逻辑不能复用，需要重复开发。

此方案只适合公司没有中间件支持并且又要做改造的情况下使用。

>如果数据有时效性，比如只需要保存2个月的数据，可以直接写增量2个月。

### binlog，数据双向同步

>当数据变更的时候(新增、更新、删除)，db 都会记录变更日志，并且同步到各个从库中，这个日志就是我们耳闻能详的 binlog。

开源的工具主要有：Canal、otter等，基本原理就是解析binlog日志，然后发送到消息中间件，客户端消费后进行处理。


**insert** 

操作可能出现的异常场景：

1. insert 操作还没插入新表，老系统就对该记录操作了一次更新，然后也吐出了一条 binlog，这时候这条 binlog 先被客户端消费，由于更新的时候如果新表内没有数据，会更新失败，更新失败后会走数据订正逻辑。
2. 数据订正的时候如果新表没有数据则会新增。这时候再操作 insert 操作就会报主键冲突。新增失败的时候也会走数据订正逻辑。

>在消费到的时候根据数据的主键ID加一把分布式锁能不能解决问题。 答案是不能解决，因为更新操作可能会更先被消费到，这时候还是会报主键重复，并且如果数据量大的情况下，加锁还会导致数据同步性能问题。


**update**

不是无脑更新的，需要加个乐观锁（where update_time < #{updateTime}），如果表里数据已经比你新了，那么就不更新，更新失败，走数据订正逻辑。如果表里数据比较老，那么更新成功。


**数据修订**

不管是 insert 操作还是 update 操作，当操作失败了以后，我们都要进行数据订正，这是为了保证最终数据一致性。

数据订正的整个过程都需要根据主键ID来进行**加分布式锁**，这是因为数据订正的时候是拿主键ID去新老表查数据，然后进行比对后才决定如何进行订正。

> 也可以不加锁，直接比较时间，看谁更新。 取值比较时，记得带上version，保证待会写入时，版本号没变化（cas比较值），避免这个比较过程中，有更新数据已经写入。


# 数据结构



# 架构设计